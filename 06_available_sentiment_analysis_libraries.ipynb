{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available sentiment analysis libraries\n",
    "\n",
    "As sentiment analysis is a common issue, many people try to prepare ML-like architectures to address it. Most of these solutions are tried to be generic, so should be applicable in any domain, however that's not always the case.\n",
    "\n",
    "The motivation behind this training is that Codete wanted to use sentiment analysis for one of the showcases we show at different conferences from time to time - it performs a realtime sentiment monitoring of tweets for given phrase and visualizing a global perception of that topic. Surpisingly, some of the best known libraries struggle with such short messages, which are typically incorrect in terms of grammar and linguistic correctness in general. Tweets have a tendency to contain a lot of phrases which don't come from the real language, like acronyms, hashtags, etc. There are also several other issues which are different the ones we have in the official English language. \n",
    "\n",
    "We believe, having a problem to be solved with Machine Learning, should never start with desiging our own model, but with a research if anyone else had a similar problem, and trying to apply their work, if possible. That was also a process we initially conducted, but existing ones didn't work well on our dataset. That's a good reason to design our own one.\n",
    "\n",
    "Nevertheless, if you have to use sentiment analysis in your project, you should keep your eye on the following libraries:\n",
    "\n",
    "## NLTK\n",
    "\n",
    "Python NLTK is a common NLP library and it already has a built-in and trained model for the sentiment analysis. Let's look at the example, as it is quite simple to be used out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'compound': -0.4588}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# It is required to download the lexicon before starting\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Create the analyzer and try it out\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(\"The last game of polish national team was awful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "\n",
    "This is another Python library which aims to address many different NLP problems. One of them is sentiment analysis. Under the hood TextBlob uses NLTK, but not directly the same algorithm, of course. Here is a short demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.4666666666666666, subjectivity=0.48888888888888893)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download the language resource used internally\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Perform the analysis on given text\n",
    "blob = TextBlob(\"The last game of polish national team was awful\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford CoreNLP\n",
    "\n",
    "Stanford Univeristy is one of the biggest research centers focused on NLP problems. CoreNLP is a toolkit of different methods used in this area in order to solve some common problems, also sentiment analysis. The library is written in Java and some papers claim it is state-of-the-art tool when it comes to that issue, so it's definitely worth giving a try.\n",
    "\n",
    "Due to the fact we're using Jupyter Notebook, it's hard to show a working example here - it has a Java interface which is not as easy to be used within this tool as the previous libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
